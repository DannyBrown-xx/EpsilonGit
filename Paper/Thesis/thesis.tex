\documentclass[11pt]{book}
\usepackage{graphicx}
\usepackage[margin=1in,bindingoffset=.2in]{geometry}
\usepackage[backend=biber, style=ieee]{biblatex}
\addbibresource{references.bib}
\usepackage[parfill]{parskip}
\usepackage{courier,textcomp,amsmath,listings, color}
\usepackage{float}
\newcommand{\code}[1]{\texttt{#1}}

% CODE HIGHLIGHTING COLOURS SET UP
% Set up for C#, Credit: http://tex.stackexchange.com/questions/124953/syntax-highlighting-in-listings-for-c-that-it-looks-like-in-visual-studio
%\setmonofont{Consolas} %to be used with XeLaTeX or LuaLaTeX
\definecolor{bluekeywords}{rgb}{0,0,1}
\definecolor{greencomments}{rgb}{0,0.5,0}
\definecolor{redstrings}{rgb}{0.64,0.08,0.08}
\definecolor{xmlcomments}{rgb}{0.5,0.5,0.5}
\definecolor{types}{rgb}{0.17,0.57,0.68}

\lstset
{
  language=Ruby,
  captionpos=b,
  %numbers=left,
  %numberstyle=\tiny,
  frame=lines,
  showspaces=false,
  showtabs=false,
  breaklines=true,
  showstringspaces=false,
  breakatwhitespace=true,
  escapeinside={(*@}{@*)},
  commentstyle=\color{greencomments},
  morekeywords={partial, var, value, get, set},
  keywordstyle=\color{bluekeywords},
  stringstyle=\color{redstrings},
  basicstyle=\ttfamily\small,
}

\begin{document}
\begin{titlepage}
	\newgeometry{margin=1in}
	\begin{center}
		{\huge Advanced Querying and Analysis\\ of Git Repositories\\}
		\vspace{1.5cm}
		{\Large \textbf{Daniel Brown} \\}
		{\Large Department of Computer Science, University of York \\}
		\vspace{1.5cm}
		\includegraphics[width=100px]{images/university-of-york-shield} \\
		\vspace{1.5cm}
		{\Large September 2015 \\}
		\vspace{1.5cm}
		\Large Supervised by Dr. Dimitris Kolovos \\
		\vspace{1.5cm}
		\Large A thesis submitted in partial fulfilment for the degree of \\ \textit{Master of Science in Advanced Computer Science}\\
		\vspace{5cm}
		\small 4,417 words as counted by Texpad.app
	\end{center}
	\restoregeometry
\end{titlepage}

\chapter*{\centering Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\begin{center}
	\parbox{350pt}{
Git is one of the most popular version control systems available \cite{gitpopularity} and, as well as many privately hosted instances, powers the well-known social programming website GitHub \cite{gitpowersgithub}.

Despite Gits popularity there are few systems available for analysing a git repository or querying it for useful metrics such as most popular commit time, largest commit, most active contributor or something more complex.

The systems that do exist to analyse Git repositories, namely GitInspector \cite{gitinspector} and Github, don't allow for custom queries to be written by the user. Meaning, for example, you cannot ask the question "What day of the week is Daniel most likely to author a commit of over 100 lines" or "Which contributor has had the highest percentage of their committed lines changed by someone else". 

This project presents a tool, called EpsilonGit, which allow users to write these custom queries by letting them interact with a git object database as a model using the Epsilon platform and its associated domain specific modelling languages. This model-based solution is then compared with existing technologies on the parameters of code complexity, speed, and extensibility by the user.
}
\end{center}

\clearpage

\section*{Acknowledgement}
I would like to take this opportunity to thank Dr. Dimitris Kolovos who not only provided support and encouragement throughout the course of this project, but also came up with the original idea of using model driven engineering to interact with git and added features into the Epsilon suite to support some of the work I was doing.

A special thank-you is extended to my parents, siblings and girlfriend who have supported me throughout the trials and tribulations of my time at York by visiting both myself and the National Railway Museum an inordinate amount of times. The same gratitude is required of my friends both from at home in Dunstable and The University of Hull, where I completed my Bachelors degree. %The museum bit is an inside joke. I'll keep it in for a laugh

\section*{Statement of Ethics}
Ethics in research is of paramount importance and therefore this project has been carried out with them in mind at every step. 

All literature, ideas and code that has been used in the formation of this project has been correctly referenced and credit has been given where it is due.

The data that my project interacts with is a local copy of a git database. The user must source this data on their own, and therefore the project doesn't have to deal with any authentication or security. EpsilonGit only gives people a different view on data they already have.

No other significant ethical issues related to this project could be identified.

\tableofcontents

\chapter{Introduction}
\label{introandbackground}
\section{Introduction and Background}
% Rough outline of git 
	% (e.g. its a distributed VCS... so people have code locally to be modelled, people use it for x functions (e.g. commit, branch, put their name to code) )
	% Why would someone what to query and analyse their git repository?
	% Some cool questions that could be asked
	
Git is a free and open source distributed version control system \cite{gitintro} that is designed to allow users to manage changes to files, often source files in a software project. This enables developers to "roll back" to a previous version of a file, see the difference between a file at two different times or determine which team member authored a line of code. 

Version control best practices suggest that a developer should be committing code a little at a time and quite often \cite{gitbestpractices}, this makes it a good place to analyse to determine an individual developer or teams working practices in retrospect.

A project manager may want to analyse a git repository to answer questions such as "How large is the average commit size?", "What time of the day are most commits made?" and "Which of my developers is committing the most code that is later replaced?". The answers to these questions may allow improvements in both quality of code and workplace practices.

Mining Software Repositories (MSR) for information to improve Software Engineering practices is a hot area of research right now with an annual dedicated conference \cite{msr2015}. MSR is the process of analysing the rich data available in these repositories to uncover interesting and actionable information about software systems \cite{theroadagainformsr} including identifying pre-existing patterns in code, and automatically linking code to bug reports -- this project aims to aid that discovery. Answering semantically challenging questions such as "Does the git fork flow enable more people to contribute to this project?" could be achieved, potentially changing the shape and attitudes of organisations.

Whilst MSR is a popular research topic a recent paper enumerating the tools used by MSR researchers found that many MSR researchers are using general purpose data mining tools rather than bespoke specialised MSR tools \cite{toolsinminingsoftwarerepositories}.

% Rough outline of modelling
	% What is modelling?
	% Why is it _possibly_ suitable for this project?
Model Driven Engineering is an approach to tackle the complexity of data, and how it is interacted with, through the use of high level abstractions called models \cite{modeldrivenengineering} and a set of Domain-specific modelling languages and Transformation engines and generators.   
	
Due to the large array of features provided by git and the widespread use of hashes and graph data structures in the underlying system it is often considered to be complex \cite{gitcomplex}\cite{githard}\cite{gitmixedmetaphors}.

The proposition of this project is that a model driven engineering solution to querying and analysing git repositories can deliver substantial productivity and quality improvements over existing approaches as it removes much of the complexity associated with git.

% Discussion of epsilon
% Discussion of the epsilon driver framework and what integrating with epsilon gets us (e.g. ability to make HTML from models, use of EOL Language, ability to run in and out of eclipse, etc)

Epsilon is a family of languages and tools for code generation, model-to-model transformation, model validation, comparison, migration and refactoring \cite{epsilonhomepage}. Whilst Epsilon comes with support for interacting with EMF, XML and several other types of model formats out-of-the-box it also has a system called the Epsilon Model Connectivity layer which allows developers to implement drivers for other types of models and structured artefacts.

Epsilon was originally developed with a focus on software engineering models (e.g. UML models), due to its modularity and extensibility it has also been used on non-model artefacts such as spreadsheets, XML documents and relational data. This project aims to bring git access capabilities to the Epsilon Platform.

The project being introduced here, EpsilonGit, will be deemed a success if it displays the following characteristics: is as fast, or faster, as competing solutions for identical queries; allows users to write custom queries in more concise and less complex code than interacting with git directly, and has coverage of the most common parts of gits features.

\section{Motivation}
% Motivation
	% Improve companies, open source projects and individuals understanding of their code and workflows
	% Encourage people to use and invest in Modelling, particularly using epsilon
	% Release it to the world and see what innovative and cool information people could get from their git repositories. With open data and software all kinds of weird shit can be done the original creator wouldn't have thought of.
The Joel Test \cite{joeltest} is often cited as a simple list of best practices for software development. Rule number 1 is to use version control software in order to aid teamwork, maintain a canonical history of source code and reduce the likelihood of losing any work. The positive impact that version control has means that many open source, individual and commercial projects use version control -- one of the most popular being git \cite{gitpopularity}. 

Although many projects use git there are very few tools for querying and analysing the metadata and other information contained within git repositories. Those that are available lack the ability to add user-designed custom queries. 

The reasons that there are few good tools for querying git repositories are varied. Firstly, Mining Software Repositories is a relatively new field --  meaning both that no one has built these tools yet and the Software Engineering community at large doesn't know of the benefits. Secondly the git API isn't the easiest to work with. Understanding the git command line requires knowledge of many Unix commands and is just one of the reasons Git is often said to be complicated \cite{gitcomplex}\cite{githard}\cite{gitmixedmetaphors}. Listing \ref{lst:gitbash} shows that to list authors by number of commits you need to have knowledge of Bash, Awk, Sort, Cut and Git itself.\\ 

\begin{lstlisting}[caption=List Authors by Number of Commits in Git Bash, label=lst:gitbash]
git log --format='\%aN <\%aE>' | awk '{arr[\$0]++} END{for (i in arr){print arr[i], i;}}' | sort -rn | cut -d\ -f2-
\end{lstlisting}

Through developing a system in which users can write their own custom queries in an easy-to-use and abstract fashion it is anticipated that teams will be able to learn more about their own workflows and where improvements can be made -- this could be particularly useful to teams using agile methodologies which lack the rigid structure of older methods such as Waterfall.

The software produced as part of this project should also make it easier to determine if git best practices \cite{gitbestpractices} are being followed. In addition to best practices some teams set project wide best practices for commit messages \cite{erlanggitcommitmessages}, users should be able to write validators to ensure these are being used.

As well as helping teams understand their git repositories this project also aims to encourage Software Engineers to learn about and invest in Model-Driven Engineering. It is the the hope of the author that combining MDE with a technology as prevalent as git may help to widen its appeal. In particular it would be great if this attracted more people to the open source Epsilon MDE platform \cite{epsilonhomepage}.

One of the more interesting aspects of the project will be opening up a world of newly accessible data to people and seeing what interesting analysis they can come up with that the author alone wouldn't have thought of.

\section{Aims and Objectives}
\label{aimsandobjectives} 
%Aims and objectives
	% Develop a solution which covers all of the most common parts of git (e.g. Object Model, Branches, Authors and Committers)
	% Develop a solution which has as fast or faster runtime for the same output as GitInspector / Github / GitSQL
	% Develop a solution which requires less code, and code of lower complexity for the same output as other solutions
	% Develop a solution which, at the same times, provides high level simple nice clean interaction whilst allowing access to low level stuff for those who also want that interaction
This project aims to implement an Epsilon Model Connectivity (EMC) driver to enable querying and analysis of git repositories from the domain-specific programming languages of the Epsilon Eclipse framework.

The objectives of the project are as follows:

\begin{enumerate}
	\item Develop a EMC solution for interacting with the most commons parts of Git (Object Model, Branches and Author \& Committer Information) through Epsilon Eclipse
	\item Optimise the solution so that it produces the same output as GitInspector in the same amount of time or less 
	\item The solution should allow developers to write queries with identical output to GitInspector and GitHub with less code, and code of less compexity
	\item The solution should provide access to all low-level properties of the covered areas of git whilst providing higher-level methods to speed up development of user-written queries
\end{enumerate}

A secondary aim of the project is to attract more users to the Epsilon Platform and model driven engineering in general using git prevalence in Software Engineering as a draw.

\section{Constraints}
There are several constraints which could have an effect on the outcome of this project. 

\begin{enumerate}
	\item This project is to be completed in the 4 months between the end of the taught portion of a Masters degree and the following September. In that time the author also has to interview for opportunities of employment so even less time can be allocated to EpsilonGit.
	\item This project is also the first full-fledged academic paper of the author and therefore his knowledge of this area is limited
\end{enumerate}

The author hopes to overcome these issues to provide a valid and novel piece of research.

\section{Report Structure}
% Report Structure
	% A paragraph or two explaining the overall flow of this document, and calling out the names of each chapter. Not repeating the table of contents, but instead highlighting important sections in prose.

This paper covers the entire process of development of EpsilonGit.

Chapter 2 covers a literature review undertaken before work was carried out, model driven engineering and the git object model are discussed in detail. Using the information ascertained in the literature review chapter 3 discusses the requirements of this project. Chapter 4 discusses several software engineering methodologies that could be followed during the course of development and a decision is made.

Chapter 5 explains the processes undertaken during the design stage, including the interaction between JGit and the Epsilon Model Connectivity layer. The actual implementation details of EpsilonGit are discussed at length in Chapter 6. Chapter 7 rounds up the practical portion of the report by explaining how several types of testing were used together to form a complete testing framework for the EMC driver.

Chapter 8 evaluates the work undertaken against the aims and objectives which were set out in section \ref{aimsandobjectives}. Conclusions from the work are drawn in Chapter 9 and potential future work ideas are provided to the reader. Finally, Chapter 10 reflects on the project as a whole and the author himself.  

\chapter{Literature Review}
% Intro paragraph "This chapter looks at the existing literature... etc"
% Section on literature about Git and the git object model
	% Conclusions drawn from the literature
		% A well known model, with some interesting idiosyncacies. Fits modelling well.
		
\label{litreview}
This chapter looks at the existing literature in the relation to the Git Object Model, Model Driven Engineering techniques, Previous attempts at analysing git repositories and techniques for interacting with object models -- such as the HTML Document Object Model -- which are similar to Git.

\section{Git and Version Control Systems}
\label{sec:git}
Version control systems (VCS) allow Software Engineers to keep a history of changes made to the files they work with. Diomidis Spinellis of Athens University of Economics and Business states that adopting a VCS can be the most important tooling improvement a Software Engineering team can make \cite{toolsofthetrade}.

Git is a version control system originally developed by Linus Torvalds, known for developing the Linux Kernel, with the goals of being fast and efficient with large projects \cite{progit}.

There are two main types of VCS, Centralised Version Control Software and Distributed Version Control Software. Centralised version control systems rely on a central server which contains the canonical source repository whilst distributed systems downloads a complete clone of the repository with a full commit history, meaning each client has a first class repository\cite{whydistributed}.

Distributed version control software has several advantages over centralised systems. Firstly they allow any developer to have write access to a repository, rather than having to submit a patch to someone with committer privileges, which lowers the barrier to entry on open source projects \cite{distributedimpactoss}. Secondly they allow cheap local branching and merging as well as reduced redundant file storage thanks to the use of changesets rather than individual file revisions \cite{distributedimpactoss}. 

Whilst distributed version control systems \cite{whydistributed}, and in particular git \cite{gitpopularity}, have become more popular than centralised version systems there are still some proponents of CVS thanks to the fact that engineers don't have to download potentially very large repositories with very large histories \cite{cvsvsvcs}.

Git uses the distributed model, meaning each computer on which a repository is used has a complete copy of its history. This makes it a good candidate for analysis as any team member will be able to be involved in the process rather than just the central repository administrator.

Although there are many methodologies for using version control systems all of them contain the same basic commands which form the majority of a users interaction with their VCS. In Git these commands are \cite{gitrefbasic}: 

\begin{table}[h]
\centering
\begin{tabular}{| l | p{9cm} |}
\hline
\textbf{Command} & \textbf{Action} \\ \hline
git clone [remote repository location] & Downloads a repository and all its history from a specified remote location \\ \hline
git add [file] & Adds a file to the git index so that its changes will be tracked \\ \hline
git commit [message] & Stores current changes to history with a message to inform other engineers why changes were made \\ \hline
git push & Sends local changes to a remote repository \\ \hline
\end{tabular}
\caption{Basic Git Commmands}
\label{tab:basic-git-commands}
\end{table}

The git community has developed several different workflows to interact with git for different types of projects and requirements of those projects \cite{gitcomparingworkflows}. 4 such examples are: 

\begin{enumerate}
	\item Centralized Workflow; which works in much the same way as a CVS would
	\item Feature Branch workflow which requires engineers to create a new branch for each feature they are working on before merging back into a main branch which is considered the production ready code
	\item The Gitflow Workflow; which is a mixture of the two previous workflows
	\item Forking Workflow; Commonly used by open source projects. A contributor makes changes in his own local repository and then requests that they be 'pulled' into the main public repository
\end{enumerate}

The many different ways of using git suggest that different analytics may also be required.

\clearpage

\section{The Git Object Model}
The core of git is a content-addressable filesystem which can store any object and assign it a hashcode by which it can be identified \cite{progit}. There are 4 main types of object stored in this system, known as the git object model, which are shown in Figure \ref{fig:gitobjectmodeldiagram}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\textwidth]{images/gitobjectmodel}
	\caption{The relationships between Git Objects}
	\label{fig:gitobjectmodeldiagram}
\end{figure} 

Each of these objects will now be discussed in more detail.

\subsection{Blob}
In git a blob is an array of bytes, which can be text or binary data, that is stored in the content-addressable file system. Blobs should not be confused with files as they are just content with no metadata such as filename, in fact if two files are added to git with exactly the same content, and therefore hashcode, they share a blob.

\subsection{Tree}
A tree object in git can be thought of as analogous to a directory in a UNIX file system. For each file in the tree a tuple is stored of the name of file, the hashcode of the blob which contains its content, and a numeric file type code \cite{gitmagic}.

A tree can also contain the names and hashcodes of other trees, allowing for a hierarchical file system, as shown in Figure \ref{fig:gitobjectmodeldiagram}. 

\subsection{Commit}
The commit object type stores information about a snapshot of the blobs and trees in the git repository at a particular time. The information includes the name and email address of the author of changes, the name and email address of the person who made the commit, the UNIX timestamp of the time the commit was made, and a message to explain why changes have been made.

A commit points at one-and-only-one root tree, which contains all the other trees and blobs that form part of that snapshot.

\subsection{Tag}
Tags specify points in history as being important. Typically people use this functionality to mark release points (v1.0, and so on) \cite{gitdocstags}. They contain the hashcode of the 1-and-only-1 commit they point to, a name (such as "v1.0") and a message explaining why the tagged commit is important \cite{gitforcomputerscientists}.

\section{Git Concepts}
Whilst the git object model is reasonably simple it enables some relatively powerful functionality.

\subsection{Branching \& Merging}
All of the git workflows described in section \ref{sec:git} make use of branching. Branches in git allow changes to be made on a separate named track diverged from the main (master) set of changes. This allows for example, in the case of a web browser, a new HTML element to be developed in a branch called 'new-html-element' whilst bug fixes can be made on the main branch. This avoids the complication of multiple different people working on multiple different features on one branch and breaking each others code and focus.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{images/basicbranching}
	\caption{A Simple Branching Scenario \cite{gitbasicbranching}}
	\label{fig:gitbranching}
\end{figure} 

Once work on a branch is complete its changes can be merged into the main branch, or any other branch. When this is done a commit is made, called a 'merge commit' to keep track of the event, in Figure \ref{fig:gitbranching} 'C2' is a merge commit.

\subsection{Forking}
Forking isn't a command in git, or indeed an object type, but rather a concept about how to copy and add to repositories. In the forking workflow \cite{forkingworkflow} a repository is cloned, and committed to as if it was a branch, before pushing changes 'upstream' to the original repository. Often pull requests are required for contributors who do not have direct write access to the original repository.

\section{Existing Git Analysis Tools}
% Section on literature pertaining to accessing git information
	% e.g. http://www.researchgate.net/publication/279058070_Gitana_a_SQL-based_Git_Repository_Inspector
	% Some info on gitinspector
	% Conclusions drawn from the literature
		% Primarily, there isnt many projects doing this. The SQL one has some drawbacks, etc.
There hasn't been any previous work on interacting with git through modelling, however there have been several pieces of software developed to allow users to extract information from their git repositories.

\subsection{Git Inspector}
Git Inspector is described as a statistical analysis tool for git repositories. The default analysis shows general statistics per author, which can be complemented with a timeline analysis that shows the workload and activity of each author \cite{gitinspector}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.4\textwidth]{images/gitinspector}
	\caption{A Sample HTML output from GitInspector \cite{gitinspector}}
	\label{fig:gitbranching}
\end{figure} 

The output from GitInspector is a HTML file with embedded CSS and JavaScript. It is implemented in Python and the queries cannot be edited by a user without editing the program itself.

By reading the code we can see that Git is accessed by GitInpector by issuing commands to the git program installed on the users computer via the system default terminal emulator, the output of git to standard io is then parsed by Gitinspector. This isn't a particularly efficient way of dealing with the git object model. %Can you reference code?


\subsection{GitStats}
GitStats is a statistics generator for git repositories. It examines the repository and produces statistics from the history of it including most common times of commits, author statistics, total number of files, and total number of tags. Similarly to GitInspector HTML is the only output format \cite{gitstatslinux}. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{images/gitstatslinux}
	\caption{A GitStats activity HTML output for the Linux Kernel 2.6 git repository \cite{gitstatslinux}}
	\label{fig:gitstatslinux}
\end{figure} 

Just like GitInspector, GitStats is written in Python and accesses git via a terminal emulator. GitStats provides more statistics than GitInspector however, they too are fixed and cannot be changed by the user without changing the programs code.

\subsection{Github Graphs}
GitHub is a social coding platform built on git \cite{gitpowersgithub}. One of the features of GitHub is Graphs, a set of visualisations of repository statistics \cite{githubgraphs}. Unlike GitStats and GitInspector the statistics are generated on the server-side rather than by a client on their own computer.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{images/githubgraphs}
	\caption{Some of the graphs which can be generated by Github Graphs \cite{githubgraphs}}
	\label{fig:githubgraphs}
\end{figure} 

Like GitInspector and GitStat the queries ran cannot be altered by the user, but additionally because everything happens on GitHubs servers and the code to generate the reports is closed source users cannot even hack the code to change things.

Unlike the aforementioned packages the results of analysis are displayed in a very modern HTML5 markup, with JavaScript that allows users to select just the information that is relevant to them, e.g. to select information between two dates.

The backend for Github Graphs is developed in Ruby and accesses git via %TODO: ???? Asked some people who work at GitHub, will have answer soon!

\subsection{Gitana}
Gitana is a system which incrementally exports git information to a relational database which can then be queried via SQL statements \cite{gitana}. One of the things that sets Gitana apart from the other systems is that it allows anyone with knowledge of SQL to write their own queries.

Before any queries can be ran against a repository using Gitana a database has to be built. In order to stop large repositories having to be built into a database often it has support for detecting changes to a git repository and incrementally adding updates. Whist this is good it can still take a reasonable amount of time for a large repository to become query-able the first time an index is built. This can take up to 2 hours per 1000 commits \cite{gitana}.

Thanks to the fact that Gitana uses a Relational Database that can be accessed via SQL it can be integrated with any system that can interact with SQL databases. The developers give examples of integrating with bug tracking software and code reviewing systems.

Gitana itself doesn't have any visual output, it just provides an interface to the data layer, however this allows anyone to build tools on top of it.

\section{Model Driven Engineering}
% More in-depth explanation of modelling
	% What is a model?
	% How do we interact with models?
	% etc?
Model Driven Engineering (MDE) is an approach to tackle the complexity of data, and how it is interacted with, through the use of high level abstractions called models \cite{modeldrivenengineering} and a set of Domain-specific modelling languages and Transformation engines and generators. 

There is some discussion in the literature \cite{basictheorymde} as to the exact definition of a model, it can be thought of as "a simplification of a system built with an intended goal in mind. The model should be able to answer questions in place of the actual system" \cite{precisedefinitionmda} or perhaps more correctly "A model is a description of a (part of) systems written in a well-defined language. A well-defined language is a language with well-defined form (syntax), and meaning (semantics), which is suitable for automated interpretation by a computer" \cite{mdaexplained}.

The author finds that the best way to think of a model is a higher-level abstraction than an object in object-oriented programming language.

A model itself is defined by a metamodel, and a metamodel can be defined by itself \cite{metamodelling}. 

Domain Specific Modelling Languages are specialised languages that enable a user to interact with models in a specific and often highly abstract way, developers use DSMLs to build applications using elements of the type system captured by metamodels and express design intent declaratively rather than imperatively \cite{modeldrivenengineering}.

Transformation engines and generators let the user generate artefacts, such as HTML documentation or source code form their models. As an example a source code generator could be used on a model of a school to create Java class files for every type of person at the school and initialisation code for object instances for each of the students.

MDE platforms, such as Epsilon, often consist of many DSMLs and Generators.

\section{Epsilon}
% About the platform
% EOL, EGX, Etc.
Epsilon, standing for Extensible Platform of Integrated Languages for mOdel maNagement, is a platform for building consistent and interoperable task-specific languages for model management tasks such as model transformation, code generation, model comparison, merging, refactoring and validation \cite{theepsilonbook}. 

The Epsilon Platform can be run as an Eclipse Application or imported into another application as a .jar library file.

Epsilon has a set of domain specific languages and generators for many different tasks based on a core language called Epsilon Object Language or EOL. 

\begin{lstlisting}[caption=An example of EOL code, label=lst:exampleEolCode]
People.all.select(p | p.age > 20 and 
  (p.career = "Computer Scientist" or p.career = "Lecturer"))
\end{lstlisting}

Out-of-the-box Epsilon supports models described in Eclipse Modelling Framework (EMF), XML and CSV formats, but additional model types can be added to Epsilon by use of the Epsilon Model Connectivity Layer.

\subsection{Epsilon Model Connectivity}
The Epsilon Model Connectivity layer enables developers to build plug-ins for Epsilon in order to allow it to access a new type of model through all of its inbuilt domain specific languages and generators \cite{theepsilonbook}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{images/epsilon-architecture}
	\caption{Epsilon Architecture \cite{emcdocs}}
	\label{fig:emc}
\end{figure}

In Figure \ref{fig:emc} it can be seen that implementing the Epsilon Model Connectivity layer allows all the 'task specific languages' to access the models information via EOL. It can also be seen that Epsilons 'built-in' model types are built using the same technology.

The functionality required of an EMC layer is described through the abstract classes which must be implemented in Java, a graphical overview of which can be seen in Figure \ref{fig:imodelinterface}. The \code{IModel} interface describes the formal parameters for functions to control basics such as storing and loading the model, accessing model elements and optionally writing changes to model elements.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{images/imodel-interface}
	\caption{The IModel Interface \cite{theepsilonbook}}
	\label{fig:imodelinterface}
\end{figure}

\section{Querying and Analysis using MDE}
% Has this kind of shit been done before? By Whom, for what? What can be learned?
%TODO: Ask Dimitris about this 

\chapter{Requirements}
\section{Problem Statement}
\label{problemstatement}
% Statement of Needs
A problem statement outlines the basic issue which the project is trying to solve. An abstract outline of the requirements of the product which could solve this problem will be discussed. This information can then be used to determine stakeholders of the process and guide the requirement solicitation process \cite{problemstatement}.

The problem statement is heavily influenced by the initial project proposal written by the project supervisor \cite{initialproposal}.

\textit{
Git is a popular distributed version control system 	that is widely used both in academia and in industry. Git provides a command-line API through which basic queries can be evaluated against local repositories (e.g. git log) but lacks facilities for expressing complex queries in a concise manner.}

\textit{
The aim of this project is to support such complex high-level queries on Git repositories.}

\textit{
Such an advanced query facility would enable the development of advanced Git repository analytics and visualisation services (e.g. using Epsilon's EGL as a server-side scripting language).}

\section{Stakeholder Identification}
\label{stakeholders}
A stakeholder is a person or organisation who influences a systemâ€™s requirements or who is impacted by that system \cite{stakeholders}, because the stakeholders influence the requirements they must be identified before requirements are written in order for the requirements to take them into account and be correct.

Direct stakeholders are people whom interact with the computer system directly as a user, whilst indirect stakeholders are those who are otherwise affected \cite{directvsindirectstakeholders}, both will be discussed in detail.

\subsection{Direct Stakeholders}
\label{directstakeholders}
\subsubsection{Git Analysts}
Project managers, team leads or individuals who want to use the software solution to analyse their git repositories using built-in queries or those developed by other people. The main "users" of the system.

\subsubsection{Query Developers}
The developers writing custom queries either for Git Analysts. An individual could be both a query developer and a git analyst, and this is the expected use case. 

\subsection{Indirect Stakeholders}
\subsubsection{Project Managers}
The people in charge of the project for which analysis is taking place. They may want to use the analysis to help them make strategic decisions about the future of the project or determine why things happened the way they did in the past.

\subsubsection{Users of Git Repositories}
Developers and other people who have contributed code or other artefacts to a git repository are stakeholders because it will be their information and work which is being analysed.

\subsubsection{End users of Code Repositories Analysed}
If the git repository for 'My Word Processor' is analysed and this results in an improvement or deterioration to the workflow for that team it could potentially have an effect on the final product and therefore the end users of 'My Word Processor'. 

\subsubsection{Epsilon Users and Developers}
One of the secondary aims of the project, as outlined in section \ref{aimsandobjectives}, is to get more people interested in Epsilon and Model Driven Engineering -- Therefore the Epsilon Developers are key stakeholders. Users of Epsilon could benefit from increased exposure of epsilon to the developer community.

\subsubsection{Project Supervisor and Author}
Both the Project Supervisor and the author of this project are invested in as good an outcome as possible within the limits in terms of time and resources available to the project. 

\section{Roles of Contributors}
The Project Supervisor, Dr. Kolovos, is the lead developer and project maintainer of Epsilon. This position means that he is well suited to representing the interests of Epsilon users and developers. As outlined in the problem statement in section \ref{problemstatement} Dr. Kolovos initially proposed this project, with the intention of being a user himself, and is therefore also a good spokesperson for project managers, users of git repositories and end users of code repositories analysed.

\section{Use cases}
Uses cases are descriptions of interaction scenarios between a system to be designed and users of the system \cite{usecase}. Figure \ref{fig:usecasediagram} shows the relationships between the direct stakeholders of the system outlined in section \ref{directstakeholders} and their associated actions.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{images/use-case-diagram}
	\caption{EpsilonGit use case diagram}
	\label{fig:usecasediagram}
\end{figure}

\section{Key Capabilities}
Through the process of identifying stakeholders in the project, developing a problem statement and having discussions with the project supervisor, who represents the interests of several of the stakeholder groups, a list of key capabilities of the software was written up.

\begin{enumerate}
	\item Ability to query information from the Git Object Model (Commits, Tags, Blobs and Trees) of an arbitrary number of git repositories using the Epsilon Framework and its associated domain-specific modelling languages
	\item Ability to generate HTML and other artefacts from the information in the Git Object Model using The Epsilon Frameworks generators
	\item To have both a high-level API for the commonly used sections of the git system, but access to native code for less commonly used sections that there wasn't time to improve code for
	\item The ability to work on large git repositories in a reasonable time
\end{enumerate} 

These key capabilities are the ones that will be focused on the most during the development stage of the project and will be most important in achieving the aims and objectives of the project outlined in section \ref{aimsandobjectives}.

\section{Stakeholder Requirements}
Stakeholder requirements refer to the requirements of the people identified in section \ref{stakeholders}. They have been decided upon in the same way as the key capabilities of the system. 

Stakeholders have an interest in both the functional and the non-functional requirements of the system. A functional requirement is the requirement of the function of a piece of software \cite{functionalrequirements}, for example "it must be able to add two numbers together", a non-functional requirement is one pertaining to operating cost, performance, reliability, maintainability portability and anything else which doesn't relate directly to the functionality of the program \cite{nonfunctionalrequirements}.

Requirements are laid out in the following style:

\begin{table}[h]
\centering
\begin{tabular}{|p{5cm}|p{5cm}|p{5cm}|}
\hline
\textbf{Identifier} & \textbf{Description} & \textbf{Success Criteria} \\ \hline
A short code to identify the requirement. Type-Function-Number format. E.g. ST-NF-1 would be the first non functional requirement for stakeholders. & A description of what the requirement entails  & What will have to be true for a requirement to have been successfully met. Should be S.M.A.R.T \cite{SMART} \\ \hline
\end{tabular}
\caption{Requirements Style}
\label{tab:requirementsstyle}
\end{table}

\subsection{Functional Requirements}
\begin{table}[H]
\centering
\begin{tabular}{|p{5cm}|p{5cm}|p{5cm}|}
\hline
\textbf{Identifier} & \textbf{Description} & \textbf{Success Criteria} \\ \hline
SH-F-1 & Git Analysts should be able to access all commonly used parts of the git API via a model driven interface &  Git Object Model (Tag, Commit, Tree, Blob) accessible via EOL \\ \hline
SH-F-2 & Git Analysts should be able to access multiple git repositories at once for comparison & Multiple repositories query-able via EOL.  \\ \hline
SH-F-3 & Git Analysts should be able to use generators to develop artefacts from their git repositories & HTML should be able to be produced via EGX files \\ \hline
SH-F-4 & Query Developers should be able to develop epsilon object language code which requires no knowledge of the underlying git repository and can therefore be distributed for others to know about & The model interface should not itself require knowledge of git repository locations \\ \hline
SH-F-5 & Git Analysts should be able to add git repositories to Epsilon Programs and Generators using the Epsilon GUI & An option should be shown to add a git repository as a model in the epsilon GUI. When clicked this should allow the user to name it and select its location \\ \hline
\end{tabular}
\caption{Functional Stakeholder Requirements}
\label{tab:functionalstakeholderrequirements}
\end{table}

\subsection{Non-Functional Requirements}
\begin{table}[H]
\centering
\begin{tabular}{|p{5cm}|p{5cm}|p{5cm}|}
\hline
\textbf{Identifier} & \textbf{Description} & \textbf{Success Criteria} \\ \hline
SH-NF-1 &  & \\ \hline
SH-NF-2 &  & \\ \hline
SH-NF-3 &  & \\ \hline
SH-NF-4 &  & \\ \hline
SH-NF-5 &  & \\ \hline
\end{tabular}
\caption{Non-Functional Stakeholder Requirements}
\label{tab:nonfunctionalstakeholderrequirements}
\end{table}


\section{System \& Software Requirements}
System and Software requirements are the requirements that don't directly interfere with the user but are required to allow the software to work as intended.

%Things that need to be done in software to enable what users need
\subsection{Functional Requirements}
\subsection{Non-Functional Requirements}

% Stakeholder Identification (whos interested in project and their roles)
	% requirements of these stakeholders
% Breakdown of functional (features) and non-functional (speed, UX) requirements
% Use case diagram

\chapter{Methodology}
% Used agile TDD based approach, discuss why this was chosen and

\chapter{Design}
% Making architecture fit between JGit and Epsilon
% Experimentation and changes necessary as things changed (for example learning more about jGit, epsilon and Java or subclassing jGit types to provide better names in EOL code and hide some of the underlying implementation)
% Language
	% Explain how expected EOL code was developed before driver was, so driver could achieve what was wanted  

\chapter{Implementation}
% Environment used
	% Epsilon Eclipse Interim (why interim?)
	% Latest version of Git
% Libraries used
	% JGit
	% Apache Commons Lang
	% etc.
% Projects
	% .git.dt (for creating new Models from git)
	% .git (main functionality of driver)
	% .git.test (tdd stuff)
	% .git.tools (some useful EOL tools for Git stuff)
% Lots of stuff about implementation decisions here
% Summary of what do to to get the system running on your own machine

\chapter{Testing}
% Explain use of TDD, both unit tests, integration and use of EOL files that it would be hoped would work with
% Automated testing
% Use of CI
% Testing against requirements
% Summary (did all test pass?)

\chapter{Evaluation}
% Does it at least fulfil all of the analysis and querying required by the two systems its competing with (github and gitinspector?)
% Case Study vs GitInspector
	% Comparison of lines of code and code complexity required for the same output
	% Comparison of Run Time on same hardware

\chapter{Conclusion}
% Project Review (Cronological rundown of what happened)
% Is this a feasible way of dealing with git analysis and querying?
	% Why? Why not?
% Whats missing?
% A success?


\section{Future Work}
% Currently read only, would be interesting to see if being able to author commits etc via epsilon could be useful. Or even the ability to change names on commits etc via http://stacktoheap.com/blog/2013/01/06/using-mailmap-to-fix-authors-list-in-git/
% Make it would with subversion, mercurial etc
% Transform from git to svn/mercurial or vice versa via ETL (lots of people would want to make this transition)
% Lots of low hanging fruit regarding performance (e.g. computing properties each time instead of storing them in memory once they've been worked out once)

\chapter{Reflection}
% Working on project whilst other 'real life' stuff happens
% Working on coming back to a project after a long time 
% TDD was great, agile working seemed to work well.
% Java code is pretty reasonable, took a little while to get into but previous C# knowledge helped
% Example EOL/EGX code works well, but might be better if more declarative 
% This is one of only a few large projects I've worked on, so it was good experience

\printbibliography

\end{document}
